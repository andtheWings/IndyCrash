---
title: "Using the KDE+ method for identifying hotspots of pedestrian/bicylist traffic crashes in Indianapolis"
date: "02/17/2020"
author: "Daniel Riggins, MD"
output:
  html_document:
    df_print: paged
---

## Background

Excerpt from the IndyCrash [project wiki](https://osf.io/hr7kz/wiki/home/):

>Hi, my name's Dan, I'm a resident pediatrician in Indianapolis. Several years ago, my good friend Mike was bicycling through the streets of Philadelphia when a car T-boned him after it ran a red light. Among other things, Mike shattered the tip of his right elbow and his head struck straight into the windshield. He likely would not have survived if he had not been wearing a helmet. He spent months recovering from complex orthopedic surgery with physical rehab.
>
>I love bicycling/walking (aka active transit). Itâ€™s a great way to build exercise into the daily routine while reducing your carbon footprint. But Mike's experience underscores why many people don't engage in active transportation--they don't feel safe on our streets. I want that to change.
>
>This project's goal is to rebuild the environment of streets in Indy. We will engage community members around the city to design interventions for the highest risk regions to pedestrians/bicyclists. We will then use randomized controlled trials to test what helps protect people with the best efficacy and dollar efficiency. 

## Intro

Indianapolis covers a lot of ground. All five boroughs of NYC make up about 80% of the land area of Indianapolis. With limited dollars, it's not practical for Indy administrators to target the entirety of the city for infrastructure upgrade. If we want to effectively advocate for improving the safety of bicyclists/pedestrians, we need to be able to provide admins with targeted regions where folks are at greatest risk of being hit by an automobile. In this report I'll be using a relatively new method for hot spot identification called ["KDE+"](http://www.kdeplus.cz/en/faq). At its heart is a tried and true technique called [kernel density estimation](https://mathisonian.github.io/kde/), but KDE+ adds the advantages of taking a network (of roads for example) as input and ensuring that outputs are statistically significant/ranked in order of risk magnitude.

```{r message=FALSE, warning=FALSE}
library(feather)
library(dplyr)
library(sf)
library(ggplot2)
library(lwgeom)
library(leaflet)
library(leaflet.extras)
```

## Data Prep

Let's start by loading our dataset of crash locations--[see here](https://nbviewer.jupyter.org/github/andtheWings/IndyCrash/blob/master/make_datasets.ipynb) for how I derived it from datasets provided by the Indiana State Police. We'll use some geometric operations to select only for crashes taking place in Indianapolis.

```{r}
# Load crashes in a "tibble" (aka dataframe)
crashes.t <- read_feather("ariesCrashes.feather") %>%
    # Subset for crashes involving walkers or bicyclists
    filter(crashActive == TRUE)

# Convert format to simple feature collection--the standard format for geographic analysis in R
crashes <- st_as_sf(crashes.t, coords = c("long","lat"), crs = 4326) %>% 
  # Transform onto a local Indiana map projection
    st_transform(crs = 7327)

# Load shapefile of marion county borders as a simple feature collection
marion <- st_read(dsn = "Marion_County_Boundary/Marion_County_Boundary.shp") %>% 
  # Transform onto a local Indiana projection
    st_transform(crs = 7327)

# Visualize
plot(marion$geometry, reset = FALSE)

# Identify which crashes took place inside of Marion County
inMarion <- st_intersects(crashes, marion, sparse = FALSE)

# Display summary of how many took place in Marion County vs not
summary(inMarion)

# Select only the crashes that took place in Marion County
marionCrashes <- crashes %>% 
  filter(inMarion == TRUE)

# Illustrate distribution of Marion County crashes
plot(marionCrashes$geometry, add = TRUE)

# marionCrashes %>%
#   # Select a subset of variables for export
#   select(date, childInvolved, crashActiveMode, numberInjured, numberDead, geometry) %>%
#     # Write crashes to a shapefile format for external use
#     st_write("Marion_Crashes/Marion_Crashes.shp")
```

Now we'll load the dataset of Indianpolis roadways available on the [OpenIndy data portal](http://data.indy.gov/datasets/street-centerlines). We'll merge streets that are arbitrarily divided into multiple segments despite the absence of an intersection.

```{r}
# Load shapefile of Marion County street lines
rawMarionStreets <- st_read("Street_Centerlines/Street_Centerlines.shp") 

MarionStreets <- rawMarionStreets %>%
  # Transform onto local Indiana projection
  st_transform(crs = 7327) %>%
  # Convert multiple line strings into a multilinestring object
  st_combine() %>%
  # Unsplit lines if they have arbitrary points dividing them
  st_line_merge() %>%
  # Convert back into a collection of linestring segments
  st_cast("LINESTRING")

plot(MarionStreets)

# Write to disk
# st_write(MarionStreets, "Marion_Streets/Marion_Streets.shp")
```

Here I tried to use the KDE+ tool myself, but could not get it to parse shapefiles on my machine. The makers also have a toolbox that can be used in ArcGIS, but I don't have a license. Eventually, I want to be able to reproducibly perform this step myself, but for now we'll use data processed and sent back to me by the team that manages the KDE+ software project. I sent them an unmodified shapefile of Marion county streets and my processed dataset of pedestrian/bicyclist crashes.

## Visualizing results

The KDE+ team sent me back a table that listed cluster segments and their intensity of risk. See their [website](http://www.kdeplus.cz/en/faq) for explanation of all variables in the table.

```{r}
# Load KDE+ clustering analysis data into a tibble (inference of data classes was incorrect so I set them all as "character" for simplicity's sake)
rawClusters <- read.csv2("KDEplusClusters.csv",
                      colClasses = c(rep("character", times = 16)))


# Jiri is one of the KDE+ analysts. Here we'll load Jiri's manipulation of Indy streets (he merged lines that were continuous with each other, but had arbitrary break points). I did a similar manipulation above, but ended up with a different number of line segments. 
JiriStreets <- st_read("Jiri_streets/Street_Centerlines_unsplit_lines_WM.shp")

# Make an intermediate dataset that loads full street segments we'll use as references to derive the cluster segments
forBuildingClusters <- rawClusters %>%
  # Generate new variables that hold relative position of the cluster's start point on the reference segment,...
  mutate(clusterStart = as.numeric(Clus_from) / as.numeric(Len_line),
         #...relative position of cluster's end point,...
         clusterEnd = as.numeric(Clus_to) / as.numeric(Len_line),
         #...and the actual geometry of the reference segment.
         referenceLines = st_geometry(JiriStreets[as.numeric(ID_line),"geometry"])) %>%
  # Convert tibble to simple feature collection
  st_sf() %>% 
  # Transform onto a local Indiana projection
  st_transform(crs = 7327)

# Initiate a list of crash cluster segments
clusterCollection <- st_linesubstring(forBuildingClusters$referenceLines[1],
                                      forBuildingClusters$clusterStart[1],
                                      forBuildingClusters$clusterEnd[1])

# Build the list by iterating through the reference geometries
for (i in 2:nrow(forBuildingClusters)) {
  # Use relative start and end positions to extract clusters from the reference segments
  newCluster <- st_linesubstring(forBuildingClusters$referenceLines[i],
                                 forBuildingClusters$clusterStart[i],
                                 forBuildingClusters$clusterEnd[i])
  # Add each new cluster to the list
  clusterCollection <- rbind(clusterCollection, newCluster)
}

# Convert to simple feature list column
clusterCollection <- st_sfc(clusterCollection, crs = 7327)

# Take the reference simple feature collection
clusters <- forBuildingClusters %>%
  # Drop the reference geometries, yielding a tibble
  st_drop_geometry() %>%
  # Add the cluster geometries as replacement
  cbind(clusterCollection) %>%
  # And convert back to simple feature collection
  st_sf()

# Set base map
m <- leaflet(options = leafletOptions(minZoom = 8)) %>%
  # Load map tiles from CartoDB
  addProviderTiles("CartoDB") %>% 
  # Set focal point of the map
  setView(lng = -86.158, lat = 39.768, zoom = 10) %>%
  # Set bounds of the map
  setMaxBounds(lng1 = -86.158 + 0.7,
               lat1 = 39.768 + 0.7,
               lng2 = -86.158 - 0.7,
               lat2 = 39.768 - 0.7) %>%
  # Add toggle to full screen
  addFullscreenControl()

# Create a continuous palette function
pal <- colorNumeric(
  # The viridis palette is good for visualizing hot spots
  palette = "viridis",
  # The bounds of the color spectrum are sourced from minimum and maximum values of a log transformation of the cluster strengths
  domain = log1p(as.numeric(clusters$Str_Dens2)))

topClusters <- clusters %>%
  # Only include the top 25 clusters
  top_n(25, as.numeric(Str_Dens2)) %>%
  # Sort the entries by hot spot strength
  arrange(desc(as.numeric(Str_Dens2))) %>%
  # Add variable that quantifies rank
  mutate(rank = 1:n()) %>%
  # Transform onto geographic CRS for interactive mapping
  st_transform(crs = 4326)

# Take your base map
m %>%
  # Add the top 25 hot spot crash cluster lines
  addPolylines(data = topClusters, 
               weight = 10,
               color = ~pal(log1p(as.numeric(Str_Dens2))),
               opacity = 0.8,
               label = ~paste0("Rank: ",as.character(rank))) %>%
  # Add legend
  addLegend(data = topClusters,
            title = "Hot Spot Strength",
            values = ~log1p(as.numeric(Str_Dens2)),
            pal = pal,
            position = "topright")
```

## Discussion

Phew, we did it. Our map above visualizes the top 25 strongest clusters of Indianapolis pedestrian/bicyclist crashes from the KDE+ analysis. I'm happy to say the locations are plausible based on local knowledge of Indy. The number 1 cluster takes place at 38th and Meridian, which unites two of the busiest thoroughfares in the city. 2 and 4 are on the IUPUI college campus. Number 5 is at College and Broad Ripple Avenues in one of our main food/cultural neighborhoods. Other areas include shopping centers, downtown, and treacherous intersections around the crossings of Fall Creek. 

In order to reinforce this analysis' validity, I need to admit something. I'm not the first to analyze density of pedestrian crashes in Indianapolis. The [Indianapolis Pedestrian Master Plan](http://indywalkways.org/wp-content/uploads/2015/10/Indianapolis_Pedestrian-Plan_DRAFT_web_Pages.pdf) from 2016 lays out an extremely sophisticated rationale for prioritizing work around the city--including consideration of pedestrian safety based on crash density (pg. 17). I seriously love this document. So much so that I made [a Google Map](https://drive.google.com/open?id=1dGRDAMTg8gzoWlKnI_06YeqyzqXfKoDp&usp=sharing) several months ago that illustrated the plan's goals. It exemplies the use of data to guide priorities for municipal development. Along with safety, the authors synthesized factors related to health, equity, walking comfort, demand, and city policy to target areas for infrastructure development. Revisiting the map now, I see they also identify 38th & Meridian, IUPUI, and Broad Ripple among others as high risk areas.

## So why did you make your own map?

It's worth considering why I bothered to do this analysis in the first place when a gold-standard document like the Indy Master Plan already exists. As much as I love the Master Plan, it lays out excellent results without showing exactly how to get there. Yes, it shares a very thoughtful high-level [document on methods](http://indywalkways.org/wp-content/uploads/2015/10/Prioritization-Methodology_FINAL.pdf), but I would still need to start from scratch in terms of code to produce the same figures (plus pay a sizeable license for use of ESRI ArcGIS). Maybe the average Indy citizen doesn't need this level of transparency and access, but as a self-fashioned citizen-scientist, I care deeply about research reproducibility. The R language and it's communities like [rOpenSci](https://ropensci.org/about/) demonstrate how powerful it can be to share data and methods. I paid exactly zero dollars to develop this project because A) Indiana(polis) graciously shares its data on infrastructure/crashes and B) R makes nearly all of its packages available and open source on the internet. Now anyone can use these scripts to repeat my work or refashion it for their own purposes. I believe that's powerful. 

## Next Steps

### Cross-verify validity with another method

To double-check my result, I'd like to compare using a similar [network-based, statistically rigorous method](https://onlinelibrary.wiley.com/doi/abs/10.1111/sjos.12255). This method also uses kernel density estimation, but employs the "heat kernel" function as the "correct analogue of the Gaussian kernel [for estimating] the occupation density of Brownian motion on the network". This probably means more to spatiotemporal statisticians, but my understanding is it accounts for how density can diffuse through nodes of a network rather than breaking each edge into a discrete target of analyis as KDE+ does. Let me know if that's at all close lol. Anyway, I should theoretically be able to perform 100% of this [method within the R scripting environment](https://rdrr.io/cran/spatstat/man/density.lpp.html). Fingers crossed.

### The built environment

I'd like to employ a mix of qualitative and quantitative methods to explore what makes these hot spots particularly high risk. Ideally, part of this phase would involve getting neighborhood residents to walk me around their streets. I want to know what they see as assets and obstacles when it comes to building a safer environment. Do you know anyone who might be interested?

### Design interventions

In the future, this project will rely heavily on local residents to guide how to improve safety around their homes. I personally think it would be super cool to paint [street murals that double as traffic calming buffers](https://www.citylab.com/transportation/2019/10/safe-streets-janette-sadik-khan-bloomberg-asphalt-art-initiative/600988/), but ultimately it would be presumptive to think I can design a local intervention better than the residents who walk, bike, drive these streets every day. Plus collaboration is more fun don't you think? Ideally, we'll eventually test the interventions with pragmatic randomized controlled trials.

## That's it for now

Stay tuned for more work. Please reach out to me on [Twitter](https://twitter.com/DanRiggins) or [Github](https://github.com/andtheWings/IndyCrash) if you have critiques/suggestions.

## Attribution and License

KDE+ tool: BÃ­l, M., AndrÃ¡Å¡ik, R., Svoboda, T., SedonÃ­k, J. KDE+. Computer software. Vers. 2.3. Olomouc: CDV - Transport Research Centre, 2020. Web. <www.kdeplus.cz/en>.

<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.
